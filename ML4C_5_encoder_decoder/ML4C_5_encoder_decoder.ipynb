{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import string\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_sequence, pack_padded_sequence, pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar, RichProgressBar\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial you'll look at building an encoder and a decoder from scratch. Specifically you'll be learning how to generate names. Generating names requires an understanding of what's in a name which is where the encoder comes in. The encoder for us will look at forming a probability distribution over characters. The decoder can then begin generating characters based on what was learned from the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>percent</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1880</td>\n",
       "      <td>John</td>\n",
       "      <td>0.081541</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1880</td>\n",
       "      <td>William</td>\n",
       "      <td>0.080511</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1880</td>\n",
       "      <td>James</td>\n",
       "      <td>0.050057</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1880</td>\n",
       "      <td>Charles</td>\n",
       "      <td>0.045167</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1880</td>\n",
       "      <td>George</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year     name   percent  sex\n",
       "0  1880     John  0.081541  boy\n",
       "1  1880  William  0.080511  boy\n",
       "2  1880    James  0.050057  boy\n",
       "3  1880  Charles  0.045167  boy\n",
       "4  1880   George  0.043292  boy"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First download a list of baby names\n",
    "url = 'https://raw.githubusercontent.com/hadley/data-baby-names/master/baby-names.csv'\n",
    "content = requests.get(url).content\n",
    "df = pd.read_csv(io.StringIO(content.decode('utf-8')))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charles</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>George</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  sex\n",
       "0     John  boy\n",
       "1  William  boy\n",
       "2    James  boy\n",
       "3  Charles  boy\n",
       "4   George  boy"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['name', 'sex']].drop_duplicates().reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl    4018\n",
      "boy     3437\n",
      "Name: sex, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['sex'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest boy name: Christopher\n",
      "shortest boy name: Ed\n",
      "longest girl name: Margueritta\n",
      "shortest girl name: Jo\n"
     ]
    }
   ],
   "source": [
    "longest_boy_idx = df[df['sex']=='boy']['name'].str.len().idxmax()\n",
    "shortest_boy_idx = df[df['sex']=='boy']['name'].str.len().idxmin()\n",
    "longest_girl_idx = df[df['sex']=='girl']['name'].str.len().idxmax()\n",
    "shortest_girl_idx = df[df['sex']=='girl']['name'].str.len().idxmin()\n",
    "\n",
    "print(f'longest boy name: {df[\"name\"].iloc[longest_boy_idx]}')\n",
    "print(f'shortest boy name: {df[\"name\"].iloc[shortest_boy_idx]}')\n",
    "print(f'longest girl name: {df[\"name\"].iloc[longest_girl_idx]}')\n",
    "print(f'shortest girl name: {df[\"name\"].iloc[shortest_girl_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create a mapping for character -> idx and idx -> character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<pad>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "chars = ['<pad>'] + ['<sos>'] + list(string.ascii_lowercase) + ['<eos>']\n",
    "n_chars = len(chars)\n",
    "char2idx = {char: idx for idx,char in enumerate(chars)}\n",
    "idx2char = {idx: char for char,idx in char2idx.items()}\n",
    "\n",
    "print(char2idx['<pad>'])\n",
    "print(idx2char[0])\n",
    "\n",
    "print(char2idx['a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a one-hot vector to represent the character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def char_to_tensor(char: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Take a character and perform a one-hot encoding in the form of a tensor\n",
    "    \"\"\"\n",
    "    ret = torch.zeros(1, n_chars)\n",
    "    ret[0][char2idx[char]] = 1\n",
    "    return ret\n",
    "\n",
    "char_to_tensor('c')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]])\n",
      "torch.Size([4, 1, 29])\n"
     ]
    }
   ],
   "source": [
    "def name_to_tensor(name: str, insert_toks: bool=False, max_len: int=None) -> torch.Tensor:\n",
    "    if insert_toks:\n",
    "        # Add the <sos> and <eos> tokens\n",
    "        ret = torch.zeros(len(name) + 2, 1, n_chars)\n",
    "        name = ['<sos>'] + list(name) + ['<eos>']\n",
    "    else:\n",
    "        ret = torch.zeros(len(name), 1, n_chars)\n",
    "        name = list(name)\n",
    "    \n",
    "    # If there is a max_len set, pad to it\n",
    "    if max_len is not None:\n",
    "        ret = torch.zeros(max_len, 1, n_chars)\n",
    "        name = name + ['<pad>']*(max_len - len(name))\n",
    "\n",
    "    for i, char in enumerate(name):\n",
    "        ret[i] = char_to_tensor(char)\n",
    "    return ret\n",
    "\n",
    "name_tensor = name_to_tensor('ab', insert_toks=True)\n",
    "print(name_tensor)\n",
    "print(name_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can tokenize the names and insert the beginning and end token as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tokenized_names(df: pd.DataFrame):\n",
    "    names = df['name']\n",
    "    ret = []\n",
    "    for name in names:\n",
    "        arr = ['<sos>'] + list(name.lower()) + ['<eos>']\n",
    "        ret.append(arr)\n",
    "    return ret\n",
    "\n",
    "tokenized_names = get_tokenized_names(df)\n",
    "max_len = max(len(name) for name in tokenized_names)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into a train/val/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0xC0FFEE)\n",
    "\n",
    "def get_train_val_test(tokenized_names, train_percent, val_percent, test_percent):    \n",
    "    names = random.sample(tokenized_names, len(tokenized_names))\n",
    "    num_train = int(len(names) * train_percent)\n",
    "    num_val = int(len(names) * val_percent)\n",
    "\n",
    "    train_names = names[0:num_train]\n",
    "    val_names = names[num_train:num_train + num_val]\n",
    "    test_names = names[num_train + num_val:]\n",
    "\n",
    "    return train_names, val_names, test_names\n",
    "\n",
    "train, val, test = get_train_val_test(tokenized_names, 0.85, 0.10, 0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can pad out the data to fixed length for our encoder and create a training pair of `(window, next_char)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_to_padded_sequences(samples: list[list[str]]):\n",
    "    padded = []\n",
    "    # Each sample is a name\n",
    "    for sample in samples:\n",
    "        # Make the sliding window\n",
    "        for idx in range(len(sample) - 1):\n",
    "            window = sample[:idx + 1]\n",
    "            next_char = sample[idx + 1]\n",
    "            padding = ['<pad>'] * (max_len - len(window))\n",
    "            padded_seq = window + padding\n",
    "            xy = [padded_seq, next_char]\n",
    "            padded.append(xy)\n",
    "    return padded\n",
    "\n",
    "def padded_sequence_to_one_hot(padded_seq: list[tuple[list[int], int]]):\n",
    "    x, y = [], []\n",
    "    for ps in padded_seq:\n",
    "        window = ps[0]\n",
    "        next_char = ps[1]\n",
    "        \n",
    "        ret_window = torch.cat([char_to_tensor(char) for char in window]).unsqueeze(0)\n",
    "        ret_char = char2idx[next_char]\n",
    "        x.append(ret_window)\n",
    "        y.append(ret_char)\n",
    "    return (torch.cat(x), torch.tensor(y).reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of the first 10 entries in the training set. Notice these are a sliding window over the name `antonette`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<sos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], 'a']\n",
      "[['<sos>', 'a', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], 'n']\n",
      "[['<sos>', 'a', 'n', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], 't']\n",
      "[['<sos>', 'a', 'n', 't', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], 'o']\n",
      "[['<sos>', 'a', 'n', 't', 'o', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], 'n']\n",
      "[['<sos>', 'a', 'n', 't', 'o', 'n', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], 'e']\n",
      "[['<sos>', 'a', 'n', 't', 'o', 'n', 'e', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], 't']\n",
      "[['<sos>', 'a', 'n', 't', 'o', 'n', 'e', 't', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], 't']\n",
      "[['<sos>', 'a', 'n', 't', 'o', 'n', 'e', 't', 't', '<pad>', '<pad>', '<pad>', '<pad>'], 'e']\n",
      "[['<sos>', 'a', 'n', 't', 'o', 'n', 'e', 't', 't', 'e', '<pad>', '<pad>', '<pad>'], '<eos>']\n"
     ]
    }
   ],
   "source": [
    "rt = samples_to_padded_sequences(train)\n",
    "for e in rt[:10]:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape torch.Size([43626, 13, 29])\n",
      "val shape torch.Size([5150, 13, 29])\n",
      "test shape torch.Size([2618, 13, 29])\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = padded_sequence_to_one_hot(samples_to_padded_sequences(train))\n",
    "val_x, val_y = padded_sequence_to_one_hot(samples_to_padded_sequences(val))\n",
    "test_x, test_y = padded_sequence_to_one_hot(samples_to_padded_sequences(test))\n",
    "\n",
    "print('train shape', train_x.shape)\n",
    "print('val shape', val_x.shape)\n",
    "print('test shape', test_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(x, y, batch_size: int, shuffle: bool):\n",
    "    dataset = TensorDataset(x, y)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "train_dataloader = get_dataloader(train_x, train_y, 1024, True)\n",
    "val_dataloader   = get_dataloader(val_x, val_y, 256, False)\n",
    "test_dataloader  = get_dataloader(test_x, test_y, 128, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use our model to predict one character at a time. Given some partial sequence of characters, predict the next one. Take for example the name \"Alex\". This will become<br>\n",
    "`['<sos>', 'a', 'l', 'e', 'x', '<eos>']`\n",
    "\n",
    "But when we train the model we're training on partial sequences to predict the next character like so:\n",
    "\n",
    "| i | input (partial seq)                 | output (next char) |\n",
    "|---|-------------------------------------|--------------------|\n",
    "| 0 | ['\\<sos>']                          |  'a'               |\n",
    "| 1 | ['\\<sos>', 'a']                     |  'l'               |\n",
    "| 2 | ['\\<sos>', 'a', 'l']                |  'e'               |\n",
    "| 3 | ['\\<sos>', 'a', 'l', 'e']           |  'x'               |\n",
    "| 4 | ['\\<sos>', 'a', ''l', 'e', 'x']     |  '\\<eos>'          |\n",
    "\n",
    "The purpose of this is to learn the weights and ultimately a good representation of a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNEncoder(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int, num_layers: int = 1,\n",
    "                dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, dropout=dropout, bidirectional=True)\n",
    "        self.fc = nn.Linear(2 * hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, seqs):\n",
    "        # [len, batch, n_chars]\n",
    "        _, h_n = self.rnn(seqs)\n",
    "        hidden_states = torch.cat((h_n[0], h_n[1]), dim=1)\n",
    "        return self.fc(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape torch.Size([13, 1, 29])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0417, -0.0423, -0.0734, -0.0599, -0.0539,  0.0248,  0.0660, -0.0188,\n",
       "         -0.0803,  0.1022, -0.0965, -0.0967, -0.0425,  0.0490, -0.0951, -0.0396,\n",
       "         -0.0502,  0.1231, -0.1715, -0.1591, -0.0556,  0.0816, -0.1551,  0.0567,\n",
       "         -0.0513,  0.0775, -0.0314,  0.0020,  0.0731]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = RNNEncoder(n_chars, 128, n_chars)\n",
    "single_batch = train_x[0].unsqueeze(1)\n",
    "print('shape', single_batch.shape)\n",
    "encoder(single_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n"
     ]
    }
   ],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, encoder: nn.Module, device='cuda'):\n",
    "        super().__init__()\n",
    "        self._device=device\n",
    "        self.encoder = encoder\n",
    "    \n",
    "    def _generic_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.permute(1, 0, 2)\n",
    "        out = self.encoder(x)\n",
    "        loss = F.cross_entropy(out, y.squeeze(1))\n",
    "        return loss\n",
    "    \n",
    "    def forward(self, seq):\n",
    "        return self.encoder(seq.to(self._device))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._generic_step(batch, batch_idx)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._generic_step(batch, batch_idx)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.Adam(self.encoder.parameters(), lr=2e-3)\n",
    "        return opt\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device is', device)\n",
    "# device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ encoder │ RNNEncoder │  146 K │\n",
       "└───┴─────────┴────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ encoder │ RNNEncoder │  146 K │\n",
       "└───┴─────────┴────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 146 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 146 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 146 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 146 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde44abec99e418eaffa539f550d7e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/anaconda/v3/envs/py39/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: \n",
       "PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 96 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/anaconda/v3/envs/py39/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: \n",
       "PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 96 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/anaconda/v3/envs/py39/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 96 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/anaconda/v3/envs/py39/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 96 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn_encoder = RNNEncoder(n_chars, 128, n_chars, num_layers=2).to(device)\n",
    "rnn_lit_model = LitModel(rnn_encoder)\n",
    "rnn_trainer = pl.Trainer(accelerator=device, max_epochs=100, log_every_n_steps=25,\n",
    "                     callbacks=[\n",
    "                        RichProgressBar(refresh_rate=50),\n",
    "                        EarlyStopping(monitor='val_loss', mode='min', patience=3)\n",
    "                     ])\n",
    "rnn_trainer.fit(rnn_lit_model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the model has trained on quite a few names and has hopefully learned a bit about names. We can test this by seeing what letter the model thinks should come next for some sequence. Let's test this with the name `ryan`. I'm choosing this name because the dataset the names came from contains two names starting with `rya`. One is `ryan` and the other is `ryann`. So we can use it to see how confident the model is that the next letter should be `n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['n'], array([0.28105763], dtype=float32))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad_partial_name(partial_name: str, max_len: int):\n",
    "    partial_seq = ['<sos>'] + list(partial_name)\n",
    "    ret = torch.zeros(max_len, 1, n_chars)\n",
    "    partial_seq = partial_seq + ['<pad>']*(max_len - len(partial_seq))\n",
    "\n",
    "    for i, char in enumerate(partial_seq):\n",
    "        ret[i] = char_to_tensor(char)\n",
    "    return ret\n",
    "\n",
    "def predict_next_letter(partial_name: str, encoder: nn.Module, n=1) -> tuple[str, float]:\n",
    "    with torch.no_grad():\n",
    "        encoder.train(False)\n",
    "        name_tensor = pad_partial_name(partial_name, max_len)\n",
    "        out = F.softmax(encoder(name_tensor), dim=-1)\n",
    "        prob, idxs = torch.sort(out, descending=True)\n",
    "        prob = prob.cpu().numpy().flatten()[:n]\n",
    "        idxs = idxs.cpu().numpy().flatten()[:n]\n",
    "        # idxs = torch.argsort(out).cpu().numpy()[:n]\n",
    "        next_char = [idx2char[idx] for idx in idxs]\n",
    "        encoder.train(True)\n",
    "    return (next_char, prob)\n",
    "\n",
    "predict_next_letter('rya', rnn_lit_model.encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked pretty well. It thinks the most likely next letter is `n` with 28% probability. Next let's see how this compares to an LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int, num_layers: int = 1,\n",
    "                dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout, bidirectional=True)\n",
    "        self.fc = nn.Linear(2 * 2 * hidden_size * num_layers, output_size)\n",
    "    \n",
    "    def forward(self, seqs):\n",
    "        # [len, batch, n_chars]\n",
    "        # h_n is a tuple where each index is [2 * num_layers, batch, hidden_size]\n",
    "        _, h_n = self.lstm(seqs)\n",
    "        # Cat and permute. Cat will combine the tuple so it's [2 * num_layers, batch, hidden_size * 2]\n",
    "        # and permute will get it so batch is first [batch, 2*num_layers, hidden_size*2]\n",
    "        hidden_states = torch.cat((h_n[0], h_n[1]), dim=-1).permute(1, 0, 2)\n",
    "        # Flatten starting at the first index so we get [batch, 2*num_layers*2*hidden_size]\n",
    "        out = torch.flatten(hidden_states, start_dim=1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape torch.Size([13, 1, 29])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0374,  0.0276,  0.0176,  0.0163,  0.0482, -0.0196, -0.0117,  0.0373,\n",
       "         -0.0335,  0.0311, -0.0508,  0.1083,  0.0243, -0.0579,  0.1008, -0.0215,\n",
       "         -0.0121, -0.0022, -0.0254,  0.0409, -0.0068, -0.0018, -0.1024,  0.0061,\n",
       "         -0.0293,  0.0791,  0.0374,  0.0848, -0.0277]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LSTMEncoder(n_chars, 128, n_chars, num_layers=2)\n",
    "single_batch = train_x[0].unsqueeze(1)\n",
    "print('shape', single_batch.shape)\n",
    "encoder(single_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type        </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ encoder │ LSTMEncoder │  587 K │\n",
       "└───┴─────────┴─────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType       \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ encoder │ LSTMEncoder │  587 K │\n",
       "└───┴─────────┴─────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 587 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 587 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 2                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 587 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 587 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 2                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed6e6adf8fe44cf88d077f8226fcb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_encoder = LSTMEncoder(n_chars, 128, n_chars, num_layers=2).to(device)\n",
    "lstm_lit_model = LitModel(lstm_encoder)\n",
    "lstm_trainer = pl.Trainer(accelerator=device, max_epochs=100, log_every_n_steps=25,\n",
    "                     callbacks=[\n",
    "                        RichProgressBar(refresh_rate=50),\n",
    "                        EarlyStopping(monitor='val_loss', mode='min', patience=3)\n",
    "                     ])\n",
    "lstm_trainer.fit(lstm_lit_model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at how the LSTM model compares when looking at the next letter for `rya`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['n'], array([0.8853272], dtype=float32))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_letter('rya', lstm_lit_model.encoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out some different architectures and see if you can reduce the loss. You can try adding dropout, an additional layer after the final hidden state, etc. You can also try reducing the learning rate over time. Now let's look at generating a name based on the model we trained. This is going to be done by using a decoder. Let's start with a greedy decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('alexandre', 0.00016087609665491233)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def greedy_decoder(encoder: nn.Module, max_len: int, partial_name=''):\n",
    "    ret = partial_name\n",
    "    curr_len = len(ret)\n",
    "    curr_tok = None\n",
    "    total_prob = 0\n",
    "    \n",
    "    while curr_tok != '<eos>' and curr_len < max_len:\n",
    "        curr_tok, prob = predict_next_letter(ret, encoder)\n",
    "        total_prob += math.log(prob)\n",
    "        if curr_tok != '<eos>':\n",
    "            ret += curr_tok\n",
    "    return ret, math.exp(total_prob)\n",
    "\n",
    "greedy_decoder(lstm_lit_model.encoder, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what does this mean? Does it mean that `alexandre` is the most probable name? No.\n",
    "This greedy decoder is a character level greedy decoder. This means that at each step it picks the most likely next character, e.g.\n",
    "\n",
    " 1\\. max `p(c | ['<sos>'])` = `a`\n",
    " \n",
    " 2\\. max `p(c | ['<sos>', 'a'])` = `l`\n",
    "<br>\n",
    "...\n",
    "\n",
    " 10\\. max `p(c | ['<sos>', 'a', 'l', 'e', 'x', 'a', 'n', 'd', 'r', 'e'])` = `'<eos>'`\n",
    "\n",
    "What we're generally looking for when decoding is the sequence that produces the highest probability. This probability might not be represented by the greedy decoder. Take for example this 2 sequence example:\n",
    "\n",
    "| sequence | probs  | overall prob  |\n",
    "|----------|--------|-------------- |\n",
    "| ['s', 'b', 'c'] | .3, .2, .2 | .012 |\n",
    "| ['a', 'b', 'c'] | .2, .8, .9 | .144 |\n",
    "\n",
    "Because in this example 's' has a higher probability of being selected, the greedy decoder would go down that path and choose `sbc` even though the overall probability of `abc` is higher. Okay great. So all we need to do is go down every path and just find the sequence that produces the highest probability. While that'd be awesome, even with this small example of 29 characters you would need to go over ~$29^{13}$ different examples. Because of this we need a better way to find a most probable output. Next let's look at a beam decoder. The beam decoder takes a beam of some size, k,  and tracks the most probable characters of that fixed width beam. Then at each step it takes each of the k candidate sequences and combines the next k most likely and finally pruned to the top k new sequence candidates. Below is what that looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['alex', 'marge', 'jacque', 'alexa', 'jacqu'],\n",
       " [0.0003029634823899965,\n",
       "  0.00018451205072100678,\n",
       "  0.0001707193587972278,\n",
       "  0.00016854112962335765,\n",
       "  1.8486967055518538e-05])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def beam_decoder(encoder: nn.Module, max_len: int, partial_name='', k=5):\n",
    "    curr_len = len(partial_name)\n",
    "    candidates = [(partial_name, 0, False)] # (seq, prob, done)\n",
    "    \n",
    "    # We automatically inject <sos> token so in this case we go max_len - 1\n",
    "    for _ in range(max_len - curr_len - 1):\n",
    "        potential_candidates = []\n",
    "\n",
    "        for seq, prob, is_done in candidates:\n",
    "            # Don't do anything if the candidate has hit <eos>\n",
    "            if is_done:\n",
    "                potential_candidates.append((seq, prob, is_done))\n",
    "                continue\n",
    "\n",
    "            next_toks, next_probs = predict_next_letter(seq, encoder, n=k)\n",
    "            for next_tok, next_tok_prob in zip(next_toks, next_probs):\n",
    "                newly_done = next_tok == '<eos>'\n",
    "                log_prob = math.log(next_tok_prob)\n",
    "                new_prob = prob + log_prob\n",
    "                new_seq = seq\n",
    "                if not newly_done:\n",
    "                    new_seq += next_tok\n",
    "                potential_candidates.append((new_seq, new_prob, newly_done))\n",
    "        # Sort and grab the k most probable\n",
    "        # How you sort is your choice. I'm choosing to initially sort by ones that are done, followed by highest probability\n",
    "        # and finally followed by selecting shorter names\n",
    "        candidates = sorted(potential_candidates, key=lambda x: (x[2], x[1], -len(x[0])), reverse=True)[:k]\n",
    "        # break\n",
    "\n",
    "    # Take all candidates and return the candidate with the exp of the prob\n",
    "    seqs = [candidate[0] for candidate in candidates]\n",
    "    probs = [math.exp(candidate[1]) for candidate in candidates]\n",
    "    return seqs, probs\n",
    "\n",
    "beam_decoder(lstm_lit_model.encoder, max_len, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case you can see that `alex` is actually more porbable than `alexandre` but because the greedy decoder saw `a` as a more likely candidate than `<eos>` it kept decoding. Another thing to notice here is that \"jacqu\" is not even in the dataset. The model learned a probability distribution and was able to determine that it could be a name. The fun thing is you can also precondition on certain characters/partial names like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brad', 'britt', 'brian', 'brand', 'bria']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_decoder(lstm_lit_model.encoder, max_len, k=5, partial_name='br')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's look at one more decoding scheme called nucleus decoding. With greedy decoding you take just the next most probable token. With beam search you take the k next probable and prune. With nucleus decoding the idea is that you take N tokens at each step until you hit some threshold percentage. The idea here is you will most likely have a long tailed distribution where a majority of the distribution is formed around a few tokens. Let's look at this in a concrete example. Consider the next letter to appear after a name starting with the letter 'a'. Take the next tokens and sort them by their probability and sample from it. Below is a quick example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9132244\n",
      "tokens needed ['l', 'n', 'r', 'd', 'u', 'm', 'b', 's', 'v']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "toks, probs = predict_next_letter('a', lstm_lit_model.encoder, n=n_chars)\n",
    "nucleus = 0.9\n",
    "curr = 0\n",
    "for i, p in enumerate(probs):\n",
    "    curr += p\n",
    "    if curr > nucleus:\n",
    "        break\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "ax.plot(probs)\n",
    "plt.title(f'Most probable from \"a\" with nucleus={nucleus}')\n",
    "plt.xticks(list(range(len(probs))), toks, rotation=70)\n",
    "plt.axvline(x=i + 1, color='r')\n",
    "plt.show()\n",
    "\n",
    "print(np.sum(probs[:i + 1]))\n",
    "print('tokens needed', toks[:i + 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case I stop taking tokens after reaching a 90% nucleus. This shows that we have a long tail and that we only need to consider 9 tokens to reach 90% of characters that should occur after the letter \"a\". Rather than keeping all of the characters, we simply sample from the characters within the nucleus. Below is what this looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('timmie', 0.00012636627036762568)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nucleus_decoder(encoder: nn.Module, max_len: int, partial_name='', nucleus=0.9):\n",
    "    partial_seq = partial_name\n",
    "    ret_prob = 0\n",
    "    while True:\n",
    "        toks, probs = predict_next_letter(partial_seq, encoder, n=n_chars)\n",
    "        curr = 0\n",
    "        for i, p in enumerate(probs):\n",
    "            curr += p\n",
    "            if curr > nucleus:\n",
    "                break\n",
    "        candidates = toks[:i + 1]\n",
    "        candidate_probs = probs[:i + 1]\n",
    "        total_prob = sum(candidate_probs)\n",
    "        # Re-distribute the probability\n",
    "        new_probs = candidate_probs / total_prob\n",
    "\n",
    "        next_char = np.random.choice(candidates, p=new_probs)\n",
    "        idx = candidates.index(next_char)\n",
    "        prob = candidate_probs[idx]\n",
    "        ret_prob += math.log(prob)\n",
    "        if next_char != '<eos>':\n",
    "            partial_seq += next_char\n",
    "\n",
    "        if next_char == '<eos>' or len(partial_seq) == (max_len - 1):\n",
    "            break\n",
    "    \n",
    "    return partial_seq, math.exp(ret_prob)\n",
    "\n",
    "nucleus_decoder(lstm_lit_model.encoder, max_len, nucleus=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can adjust the nucleus to allow for more diverse possibilities. For instance, a nucleus of 0 will be the same as the greedy decoder, which a nucleus of 1 will sample across all options. Of course it's a sample, so you'll still end up with more likely characters but it can help introduce some noise for varied output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a65da5cbd383c2a22be39562d174f1996838645f0f2da213f12068eea680f03e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
